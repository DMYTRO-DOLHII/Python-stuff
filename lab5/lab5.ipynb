{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "%pip install openpyxl\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport cv2\nfrom PIL import Image, ImageDraw\nimport os\n\n\ndef load_data(file_path: str, variant: int):\n    \"\"\"\n    Load data from an Excel file and retrieve data for the given variant.\n    \"\"\"\n    df = pd.read_excel(file_path)\n    print(f\"Loaded DataFrame:\\n{df}\")\n    \n    # Assuming variant is an index in the DataFrame\n    data = df.iloc[variant]  # Replace with correct indexing logic if needed\n    print(f\"Data for Variant {variant}:\\n{data}\")\n    return data\n\n\ndef detect_face_and_eyes(image_path: str):\n    \"\"\"\n    Detect face and eyes in an image using Haar Cascade.\n    \"\"\"\n    # Load the cascades\n    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n    eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_eye.xml\")\n    \n    # Read the image\n    img = cv2.imread(image_path)\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    \n    # Detect faces\n    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n    if len(faces) == 0:\n        raise ValueError(\"No faces detected in the image.\")\n    \n    # Assume the first detected face is the target\n    x, y, w, h = faces[0]\n    face = img[y:y+h, x:x+w]\n    \n    # Detect eyes within the face region\n    face_gray = gray[y:y+h, x:x+w]\n    eyes = eye_cascade.detectMultiScale(face_gray)\n    if len(eyes) < 2:\n        raise ValueError(\"Could not detect both eyes in the face.\")\n    \n    return img, (x, y, w, h), eyes[:2]  # Return the first two detected eyes\n\n\ndef add_glasses(image, face_coords, eyes, color=(252, 3, 11), thickness=1):\n    \"\"\"\n    Add circular glasses to an image based on detected face and eye coordinates.\n    \"\"\"\n    x, y, w, h = face_coords\n    eye1, eye2 = eyes\n    \n    # Unpack eye coordinates (relative to the face)\n    ex1, ey1, ew1, eh1 = eye1\n    ex2, ey2, ew2, eh2 = eye2\n    \n    # Calculate eye centers (relative to the original image)\n    eye1_center = (x + ex1 + ew1 // 2, y + ey1 + eh1 // 2)\n    eye2_center = (x + ex2 + ew2 // 2, y + ey2 + eh2 // 2)\n    \n    # Calculate radius of the glasses based on eye dimensions\n    radius = max(ew1, eh1, ew2, eh2) // 3 + 10  # Add padding for the glasses\n    \n    # Draw glasses\n    cv2.circle(image, eye1_center, radius, color, thickness)\n    cv2.circle(image, eye2_center, radius, color, thickness)\n    \n    # Draw bridge (line between the glasses)\n    line_start = (eye1_center[0] + radius, eye1_center[1])\n    line_end = (eye2_center[0] - radius, eye2_center[1])\n    cv2.line(image, line_start, line_end, color, thickness // 2)\n    \n    # Optionally draw arms of the glasses\n    cv2.line(image, (eye1_center[0] - radius, eye1_center[1]), (eye1_center[0] - radius - 30, eye1_center[1]), color, thickness // 2)\n    cv2.line(image, (eye2_center[0] + radius, eye2_center[1]), (eye2_center[0] + radius + 30, eye2_center[1]), color, thickness // 2)\n    \n    return image\n\n\ndef process_image(data, image_path, output_path, color=(252, 3, 11), thickness=5, resize_dim=(600, 600)):\n    \"\"\"\n    Process the image: detect face, add glasses, center face, and resize.\n    \"\"\"\n    # Detect face and eyes\n    img, face_coords, eyes = detect_face_and_eyes(image_path)\n    \n    # Add glasses\n    img_with_glasses = add_glasses(img, face_coords, eyes, color=color, thickness=thickness)\n    \n    # Crop to center the face\n    x, y, w, h = face_coords\n    face_centered = img_with_glasses[max(0, y-h//2):y+h+h//2, max(0, x-w//2):x+w+w//2]\n    \n    # Resize to specified dimensions\n    resized = cv2.resize(face_centered, resize_dim)\n    \n    # Save the processed image\n    cv2.imwrite(output_path, resized)\n    print(f\"Processed image saved to: {output_path}\")\n\n\n# Example usage\nvariant = 2  # Replace with your variant\ndata = load_data(\"lab6.xlsx\", variant)\n\nimage_path = \"images/longbottom.jpg\"  # Replace with your input image path\noutput_path = \"output-white-slim.jpg\"\n\nprocess_image(data, image_path, output_path, color=(255, 255, 255), thickness=4)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Loaded DataFrame:\n   N         file name image size glasses color  line width\n0  1  emma-watson2.jpg    300x300           red           2\n1  2   emma-watson.jpg    400x400          blue           3\n2  3         draco.jpg    700x700          cian           4\n3  4    longbottom.jpg    600x600       magenta           5\n4  5    ron_wesley.jpg    500x500        yellow           6\nData for Variant 2:\nN                        3\nfile name        draco.jpg\nimage size         700x700\nglasses color         cian\nline width               4\nName: 2, dtype: object\nProcessed image saved to: output-white-slim.jpg\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}